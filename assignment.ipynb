{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assignment.ipynb","provenance":[{"file_id":"1zLg8KDovmYmXsc3HcpVRNyU-XouJY4C9","timestamp":1630683886599},{"file_id":"0B_k471A7UcJSUS1ZWTNsWWV4T21CanBvME9iTUlXaUQtQlQw","timestamp":1554849290453}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"yerWQD2Tzokl"},"source":["# Import Modules and Prerequisites\n","Please use this section to import any necessary modules that will be required later in this notebook like the example given."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-08-30T08:02:19.275150Z","start_time":"2019-08-30T08:02:09.413650Z"},"id":"GCx876Ilzokm"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle\n","import json\n","import re\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# NLP task"],"metadata":{"id":"il8e-reUP7S_"}},{"cell_type":"markdown","source":["# Note: There is no expectation of coding a highly sofisticated solution in a small time window. Each question can be answered with a short code example and a possible written explanaton of the elaborate approach."],"metadata":{"id":"nwbyB0dml6RU"}},{"cell_type":"markdown","metadata":{"id":"BgW7ibSYP-eK"},"source":["## A common AdSquirrel microservice's task is to predict whether an article is Brand Safe or not (appropriate for the general audience, similar to SFW-NSFW)."]},{"cell_type":"markdown","metadata":{"id":"2mRW73Aazokp"},"source":["## Load and examine dataset"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-08-30T08:03:13.679645Z","start_time":"2019-08-30T08:03:13.645578Z"},"id":"RvzuTC24zokq"},"source":["df = pd.read_csv('assignment.csv')\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7rNAWFkpJNOJ"},"source":["## 1. Train a classifier on this dataset that will reach an acceptable accuracy score."]},{"cell_type":"markdown","metadata":{"id":"hXWSw3VraEBL"},"source":["#### Feel free to follow any design choices you feel fit the problem best."]},{"cell_type":"markdown","metadata":{"id":"lBkuIMkren2H"},"source":["#### Briefly describe your approach in markdown cells, along with any necessary comments on your choices."]},{"cell_type":"markdown","metadata":{"id":"ZuRU8jnGMoty"},"source":["#### Explain your choices with the appropriate evaluation plots - analysis"]},{"cell_type":"code","source":[""],"metadata":{"id":"nRuD2Jc2Ie41"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"97X2QamRrxw8"},"source":["## 2. Load a real-world, unseen (test) dataset and evaluate your best model"]},{"cell_type":"markdown","source":["### The goal is to approach the classification accuracy of the train dataset on the test dataset, without using the latter for training. Describe any challenges (if they exist) and code your solution below following the same guidelines "],"metadata":{"id":"4LoIT1gXEi_0"}},{"cell_type":"code","metadata":{"id":"ZdnAtj5cr1bQ"},"source":["df_unseen = pd.read_csv('assignment_unseen.csv')\n","df_unseen.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0JqQXHnvO3_v"},"source":["## 3a. Another important task is to perform topic classification on the same datasets, but there are no available labels. You can use the entirety of data you have at your disposal. Describe possible approaches to this problem and code the most robust solution of your choice. "]},{"cell_type":"code","source":[""],"metadata":{"id":"pdSXQbB6IcyL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5MGHPQvbPrje"},"source":["## 3b. Supposing these are last week's news and we wish to extract the latest circulating trends in order to present them to our clients, how could we approach the problem of trend extraction via NLP? Either code or describe on a high-level the best possible approach that comes to mind. (This question may be connected to the previous one depending on your solution, which is acceptable)."]},{"cell_type":"markdown","metadata":{"id":"9etHJwAYQwsL"},"source":["##### Hint: Proper text preprocessing may assist in this task, if not done already."]},{"cell_type":"code","source":[""],"metadata":{"id":"1bBK7f8XIjdh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bz21CdLRxzZx"},"source":["## 4. (Optional) Discussion. Feel free to answer some or all of the following questions to the best of your knowledge."]},{"cell_type":"markdown","source":["#### Coding is optional and not expected below, except for the case you wish to accompany your answer with example code."],"metadata":{"id":"Rtz3gO-nKNsF"}},{"cell_type":"markdown","source":["#### 4a. Suppose there is a complete labeled topic classification dataset available (hundreds of thousands of articles). Are there any changes in your design choices that would lead to a more accurate model?"],"metadata":{"id":"wANoew3fJOev"}},{"cell_type":"code","source":[""],"metadata":{"id":"4yo9GoGuKKHl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4b. In order to meet production requirements, the model needs to have as close to 20 ms latency as possible. Latency is measured as a single live prediction's time on CPU, added to the time needed to load a saved model into a microservice (directly impacted by the saved model's total size in MB). Are the models created in this assignment production ready? If not, are there any ways to improve prediction latency that come to mind? What about a model initially trained on the complete dataset which would probably be larger? "],"metadata":{"id":"g9MXQEWIJjPB"}},{"cell_type":"code","source":[""],"metadata":{"id":"Z9YWuQrBOggL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4c. Would any of the solutions presented above impact model accuracy? How could we make sure that accuracy does not fall below a desired threshold?  "],"metadata":{"id":"qn02z4UjNxJM"}},{"cell_type":"code","source":[""],"metadata":{"id":"0avGbLF_JN3O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4d. If our model from question 2. was well within latency constraints and you had sufficient time equivalent to a small independent project, how could you potentially improve the model's accuracy on task 2 without a heavy latency sacrifice? (Simply importing a huge Transformer model is not a viable solution.)"],"metadata":{"id":"8_51UVhHOjNP"}},{"cell_type":"code","source":[""],"metadata":{"id":"-JcIWMbYOiPH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4e. Our deployed models handle ~50.000 predictions on unique articles per day. What are the challenges of evaluating an ML model on such a scale? What could we do to approximately evaluate our model's performance every week while unable to hand-label the entirety of our predictions?"],"metadata":{"id":"yNF_uxWgo0yj"}},{"cell_type":"code","source":[""],"metadata":{"id":"4N4PujGTphp8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Analytics Task"],"metadata":{"id":"p6Gcvqx5QPNN"}},{"cell_type":"markdown","source":["## You have received a dataframe that contains some ML models' predictions on recent articles (text and title is irrelevant in this case) , as well as a json file containing the most trending named entities during the same time period."],"metadata":{"id":"3kaQLOCUoU-m"}},{"cell_type":"markdown","source":["## Suppose we have to create a dashboard regarding recent trends in News Articles. Use the visualization technique of your choice to extract some relevant patterns in our predictions , taking into consideration the separation due to Brand Safety in your plots."],"metadata":{"id":"f91b637Xos_U"}},{"cell_type":"code","source":["df = pd.read_csv(\"assignment_analytics.csv\")\n","\n","with open(\"trending_entities.json\") as f:\n","  trending_entities = json.load(f)\n","\n","df.head()"],"metadata":{"id":"r7pMl5F8QQ8L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-9uwDOUzolE"},"source":["# Thank you in advance"]},{"cell_type":"code","source":[""],"metadata":{"id":"zl7Y4h3VQOlk"},"execution_count":null,"outputs":[]}]}